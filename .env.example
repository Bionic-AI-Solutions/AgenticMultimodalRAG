# =============================================================================
# AGENTIC MULTIMODAL RAG SYSTEM - ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and update values for your environment
# For Docker Compose: use 'localhost' or service names
# For Kubernetes: use service DNS names (e.g., milvus.milvus.svc.cluster.local)

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
NODE_ENV=development
APP_NAME=agentic-multimodal-rag
APP_VERSION=1.0.0
APP_PORT=8000
APP_HOST=0.0.0.0
DEBUG=true
LOG_LEVEL=INFO

# =============================================================================
# MILVUS VECTOR DATABASE CONFIGURATION (Required)
# =============================================================================
# Vector database for storing and searching embeddings
MILVUS_HOST=localhost
MILVUS_PORT=19530

# =============================================================================
# MINIO OBJECT STORAGE CONFIGURATION (Required)
# =============================================================================
# S3-compatible storage for document files
MINIO_HOST=localhost:9000
MINIO_PORT=9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_SECURE=false
MINIO_BUCKET=rag-docs
MINIO_REGION=us-east-1

# =============================================================================
# POSTGRESQL DATABASE CONFIGURATION (Required)
# =============================================================================
# Relational database for metadata storage
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres
POSTGRES_SSL=false
POSTGRES_POOL_MIN=2
POSTGRES_POOL_MAX=10
POSTGRES_CONNECTION_TIMEOUT=60000

# Database URL (alternative format)
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres

# =============================================================================
# REDIS CONFIGURATION (Optional)
# =============================================================================
# Caching and session management
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_URL=redis://localhost:6379/0

# Redis Connection Pool
REDIS_POOL_SIZE=10
REDIS_CONNECT_TIMEOUT=10000
REDIS_COMMAND_TIMEOUT=5000

# =============================================================================
# NEO4J GRAPH DATABASE CONFIGURATION (Required)
# =============================================================================
# Graph database for knowledge graph and relationship storage
NEO4J_URI=bolt://localhost:7687
NEO4J_AUTH=neo4j/neo4jpassword
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4jpassword

# Neo4j HTTP endpoint (for browser access)
NEO4J_HTTP_URI=http://localhost:7474

# =============================================================================
# EXTERNAL AI SERVICES CONFIGURATION (Required)
# =============================================================================
# These services handle embeddings, STT, TTS, and LLM inference
# Update these URLs to point to your AI infrastructure

# Routing API for embeddings (Jina, Nomic models)
AI_ROUTING_API_URL=http://192.168.0.20:8001

# Speech-to-Text service for audio transcription
STT_SERVICE_URL=http://192.168.0.20:8002

# Text-to-Speech service (optional)
TTS_SERVICE_URL=http://192.168.0.20:8003

# vLLM service for LLM inference (optional)
VLLM_BASE_URL=http://192.168.0.20:8000

# =============================================================================
# LLM BACKEND CONFIGURATION (Required for Agentic Features)
# =============================================================================
# Backend for agentic query decomposition and plan generation
# Options: "local" (Ollama), "openai" (future), "mock" (testing)
LLM_BACKEND=local

# Ollama Configuration (for LLM_BACKEND=local)
OLLAMA_HOST=192.168.0.199
OLLAMA_PORT=11434
OLLAMA_MODEL=deepseek-r1:8b

# OpenAI Configuration (for LLM_BACKEND=openai - future support)
# OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_MODEL=gpt-4
# OPENAI_MAX_TOKENS=2000
# OPENAI_TEMPERATURE=0.7

# =============================================================================
# MODEL STORAGE CONFIGURATION (Optional)
# =============================================================================
# Only needed if using local models instead of external AI services
# For Docker: use /opt/ai-models or mounted volume path
# For local dev: use your local model directory
HF_HOME=/opt/ai-models
TRANSFORMERS_CACHE=/opt/ai-models
MODEL_DIR=/opt/ai-models

# HuggingFace token (optional, for private models)
# HUGGINGFACE_HUB_TOKEN=your-huggingface-token-here

# Model paths (if using local models)
JINA_MODEL_NAME=jinaai/jina-embeddings-v2-base-en
JINA_MODEL_PATH=/opt/ai-models/jinaai__jina-embeddings-v2-base-en

NOMIC_MODEL_NAME=nomic-ai/colnomic-embed-multimodal-7b
NOMIC_MODEL_PATH=/opt/ai-models/nomic-ai__colnomic-embed-multimodal-7b

WHISPER_MODEL_NAME=openai/whisper-base
WHISPER_MODEL_PATH=/opt/ai-models/openai__whisper-base

# =============================================================================
# AUTHENTICATION & SECURITY (Optional)
# =============================================================================
# JWT configuration for API authentication
JWT_SECRET=your-super-secret-jwt-key-min-32-chars-for-rag-system
JWT_EXPIRES_IN=7d
JWT_REFRESH_EXPIRES_IN=30d

# Encryption keys
ENCRYPTION_KEY=your-32-char-encryption-key-here
HASH_ROUNDS=12

# CORS Configuration
CORS_ORIGIN=http://localhost:3000,http://localhost:3001
CORS_CREDENTIALS=true

# =============================================================================
# LOGGING & MONITORING (Optional)
# =============================================================================
LOG_FORMAT=json
LOG_FILE_ENABLED=true
LOG_FILE_PATH=./logs/app.log
LOG_MAX_FILES=5
LOG_MAX_SIZE=10m

# Sentry (Error Tracking) - Optional
# SENTRY_DSN=your-sentry-dsn-here
# SENTRY_ENVIRONMENT=development

# =============================================================================
# RATE LIMITING (Optional)
# =============================================================================
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
RATE_LIMIT_SKIP_SUCCESSFUL_REQUESTS=false

# =============================================================================
# EDGE GRAPH CONFIGURATION (Optional)
# =============================================================================
# Configuration file for graph expansion and edge types
EDGE_GRAPH_CONFIG_PATH=config/edge_graph.yaml
EDGE_GRAPH_HOT_RELOAD=true

# =============================================================================
# FILE PROCESSING CONFIGURATION (Optional)
# =============================================================================
MAX_FILE_SIZE=104857600
ALLOWED_FILE_TYPES=pdf,txt,docx,jpg,png,mp3,mp4,csv
TEMP_DIR=/tmp/rag-uploads

# =============================================================================
# EMBEDDING CONFIGURATION (Optional)
# =============================================================================
EMBEDDING_DIMENSION=768
CHUNK_SIZE=512
CHUNK_OVERLAP=102
SEARCH_TOP_K=10
SEARCH_METRIC_TYPE=IP

# =============================================================================
# CACHING CONFIGURATION (Optional)
# =============================================================================
CACHE_TTL=3600
CACHE_MAX_SIZE=1000
CACHE_ENABLED=true

# =============================================================================
# FASTAPI MCP CONFIGURATION (Optional)
# =============================================================================
# Base URL for FastAPI MCP tool integration
# MCP_BASE_URL=http://localhost:8000/mcp

# =============================================================================
# FEATURE FLAGS (Optional)
# =============================================================================
FEATURE_AGENTIC_REASONING=true
FEATURE_TEMPORAL_KNOWLEDGE=true
FEATURE_VECTOR_SEARCH=true
FEATURE_MULTIMODAL=true
FEATURE_GRAPH_EXPANSION=true
FEATURE_EDGE_GRAPH=true

# =============================================================================
# DEVELOPMENT CONFIGURATION (Optional)
# =============================================================================
HOT_RELOAD=true
API_DOCS_ENABLED=true
API_DOCS_PATH=/docs

# Testing
TEST_DB_NAME=rag_test_db
TEST_REDIS_DB=1

# =============================================================================
# DEPLOYMENT CONFIGURATION (Optional)
# =============================================================================
CONTAINER_PORT=8000
HEALTH_CHECK_ENDPOINT=/health
READINESS_CHECK_ENDPOINT=/ready

# Kubernetes
K8S_NAMESPACE=default
K8S_SERVICE_NAME=rag-service

# =============================================================================
# SECURITY CONFIGURATION (Optional)
# =============================================================================
ALLOWED_HOSTS=localhost,127.0.0.1,192.168.0.0/16
SECURE_SSL_REDIRECT=false
SECURE_HSTS_SECONDS=0
SECURE_HSTS_INCLUDE_SUBDOMAINS=false
SECURE_HSTS_PRELOAD=false

# =============================================================================
# PERFORMANCE CONFIGURATION (Optional)
# =============================================================================
WORKER_PROCESSES=4
WORKER_CONNECTIONS=1000
KEEPALIVE_TIMEOUT=65
CLIENT_MAX_BODY_SIZE=100M
